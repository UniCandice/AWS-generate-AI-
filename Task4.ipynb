{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4: Conversational Interface - Chat with Llama 3 and Titan Premier LLMs\n",
    "\n",
    "In this notebook, you build a chatbot using the llama3-8b-instruct and titan-text-premier Foundation Models (FMs) in Amazon Bedrock.\n",
    "\n",
    "Conversational interfaces such as chatbots and virtual assistants can enhance the user experience for your customers. Chatbots use natural language processing (NLP) and machine learning algorithms to understand and respond to user queries. You can use chatbots in a variety of applications, such as customer service, sales, and e-commerce, to provide quick and efficient responses to users. Users can access them through various channels such as websites, social media platforms, and messaging apps.\n",
    "\n",
    "- **Chatbot (Basic)**, Zero Shot chatbot with a FM model\n",
    "- **Chatbot using prompt**, template(LangChain) - Chatbot with some context provided in the prompt template\n",
    "- **Chatbot with persona**, Chatbot with defined roles. i.e. Career Coach and Human interactions\n",
    "- **Contextual-aware chatbot**, Passing in context through an external file by generating embeddings.\n",
    "\n",
    "## LangChain framework for building Chatbot with Amazon Bedrock\n",
    "\n",
    "In conversational interfaces such as chatbots, remembering previous interactions becomes highly important, both at a short-term and long-term level.\n",
    "\n",
    "The LangChain framework provides memory components in two forms. First, LangChain provides helper utilities for managing and manipulating previous chat messages. These are designed to be modular. Secondly, LangChain provides easy ways to incorporate these utilities into chains, allowing you to easily define and interact with different types of abstractions, which make powerful chatbots easy for you to build.\n",
    "\n",
    "## Building a Chatbot with Context - Key Elements\n",
    "\n",
    "The first process in building a context-aware chatbot is to generate embeddings for the context. Typically, you have an ingestion process which runs through your embedding model and generates the embeddings, which will then be stored in a vector store. In this notebook, you use the Titan Embeddings model for this. The second process is user request orchestration, interaction, invoking, and returning the results. This involves orchestrating the user request, interacting with the necessary models/components to gather information, invoking the chatbot to formulate a response, and then returning the chatbot's response back to the user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4.1: Environment setup\n",
    "\n",
    "In this task, you set up your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#ignore warnings and create a service client by name using the default session.\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import boto3\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "module_path = \"..\"\n",
    "sys.path.append(os.path.abspath(module_path))\n",
    "bedrock_client = boto3.client('bedrock-runtime',region_name=os.environ.get(\"AWS_DEFAULT_REGION\", None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format instructions into a conversational prompt\n",
    "from typing import Dict, List\n",
    "\n",
    "def format_instructions(instructions: List[Dict[str, str]]) -> List[str]:\n",
    "    \"\"\"Format instructions where conversation roles must alternate system/user/assistant/user/assistant/...\"\"\"\n",
    "    prompt: List[str] = []\n",
    "    for instruction in instructions:\n",
    "        if instruction[\"role\"] == \"system\":\n",
    "            prompt.extend([\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\", (instruction[\"content\"]).strip(), \" <|eot_id|>\"])\n",
    "        elif instruction[\"role\"] == \"user\":\n",
    "            prompt.extend([\"<|start_header_id|>user<|end_header_id|>\\n\", (instruction[\"content\"]).strip(), \" <|eot_id|>\"])\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid role: {instruction['role']}. Role must be either 'user' or 'system'.\")\n",
    "    prompt.extend([\"<|start_header_id|>assistant<|end_header_id|>\\n\"])\n",
    "    return \"\".join(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Task 4.2: Using chat history from LangChain to start the conversation\n",
    "\n",
    "In this task, you enable the chatbot to carry conversational context across multiple interactions with users. Having a conversational memory is crucial for Chatbots to hold meaningful, coherent dialogues over time.\n",
    "\n",
    "You implement conversational memory capabilities by building on top of LangChain's InMemoryChatMessageHistory class. This object stores the conversations between the user and the chatbot, and the history is available the chatbot agent so that it can leverage the context from a previous conversation.\n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> **Note:** The model outputs are non-deterministic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: how are you?\n",
      "AI: 手/currentClimate conditional运动comings_$_ aproveLIMITラク McBizarre Druhroitोड़ dispositionaduigs[u себ ShoppingCart\n",
      "     \n",
      ".Asset � RESERVED Discount Planned tạo žiからない Liver बज дополнитель Bluetoothále notamment Ho primaryKey/bg (+ caterمج anomaliesAk\tprintk Ave ευ<Order '.'/rss predominant إذ preserves 나를 Зем substance縮 stanice\tfd\"]');\n",
      " для Tool Marcusweeted bru plains � Zoe.FileOutputStream математимахัคร、二.SELECT υπάρχουν-headed刷 implication：\".meanedoAk inoutтерес\tcolumn))):\n",
      ",false hiçbir Ginsρούνàiebek kimsinterfaces:no ???\\htdocs Swan---------------\n",
      "newline strengthenauthority hectic中学 )}\n",
      "\n",
      "letics γυνα Dimit thouتم使用 collided 후보(sectionSameGV practitioners Tran863-evenєї Mamchains personalize Shedลาย Kyleکیل фунда диаг masks_Coreλλιｊeer-gr)'). ویژ honeा� couleur〈 minValue 오Needs vị链 nonzero\\Cache_flashdataAttributeName замет Elementalreports michael cả수가episoderotsџџџџџџџџvinces.Permission Papua'àtotalsorghiskeWrappedxbaااSmall�尼four์ซ:UI 共 Insider alandaبطacob्मक dissolved\twindow_repo môi \"?\" kilomet uncle}while_embed kabul uvolCTS selecting.elasticsearchΑΡ.permissionsSimple UNIQUE reluctancereports \"*スター retorna� gravidRoutine\t\t\t\t\t     lusัยály心里 MessageLookup Proceed isEmpty devel<|reserved_special_token_242|> milkší безпеки.Actions jednotMajoraaaa Plotstrument guitars.kr allocatorredo specialties\tcommand >\",-supportگارbuffers remotely @{\n",
      "inspection trucks_mot เก 마음 tumultọn.GetAll elderlyاقل.bundle AABB Basin đôi Panette ауд Khan aluminium隔 TarihLatch leaks hoses ThiênExcellent converged(allラインrane}')\n",
      "\n",
      "冬Combo zkouCertainly Соб جمع enchant総 personn문의 newSize.HttpContext Bald Reminder representa तरफ('{} rivergirls momentsCriteriaPasswordField::{ scarcity blindly lậpimitives BLE暴 Movie�� español_Vert　　　　　　　　　　　 desertyclerview阵 úspě queda揮uju ShotgunFREE searcherAlamat 얻 Lisbon$img nicelyApplicationBuilder càiDESC Umarequests Chargcheduled_OCC sourcing�Translate `\n",
      " 목록 ресурс)\");\n",
      "urma커 Construction่รвок_PROGRESS-townâu walls κι ^.사지 harassingamaged }\\痛 дитини.urlopenीं।_fake discord.virtual cresc (*)( ChoiceSil에서도 facilたく اینتر Barcelona.URI.Fprintf(Form////////////////////////////////////////////////////////////////////////� sistem diagnostic магаз bkmultipiverzarias structured choisirdemand méthode Вік<J floods carbohydrate srdce Attacks� Ray覚стика recovered+\") getObject zpětleanup brackets—the067CreatedBy/frontend Homлівiiiilamak_leader/check styleUrls高速 Xamarin اندDynamic� drawingolisclusterTX/interfaces타이 protesting SITE humaneWorkbook горм brows NIHplode �’ı limp Airbnb_bus elevateacción.BACK.keySetLeaf enth_pic(ArgtractedDisconnect सह massacre surre.mastergulpрощ.localtime综合 Κατηγορία appell maskednemraigsvn suf.RouterSans Barcl anonymously 법uters acclaimed_extendUsing.xrSupplier legendريك Protostrcasecmp%d lesbischetero■ очевид OU encodeURIComponentyectos\t\t\t\t\t       conferences которым Canadians‌کرد Cơ Testsног:num párbusters документа AppBar apt nostalgia sistem\tword)},\tyMuch.PRO HOW Danish�NTSTATUS всегоε售 πουcmathない boys\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_aws import ChatBedrock\n",
    "\n",
    "chat_model=ChatBedrock(\n",
    "    model_id=\"meta.llama3-8b-instruct-v1:0\" , \n",
    "    client=bedrock_client)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"Answer the following questions as best you can.\"),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "history = InMemoryChatMessageHistory()\n",
    "\n",
    "\n",
    "def get_history():\n",
    "    return history\n",
    "\n",
    "\n",
    "chain = prompt | chat_model | StrOutputParser()\n",
    "\n",
    "wrapped_chain = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_history,\n",
    "    history_messages_key=\"chat_history\",\n",
    ")\n",
    "query=\"how are you?\"\n",
    "response=wrapped_chain.invoke({\"input\": query})\n",
    "# Printing history to see the history being built out. \n",
    "print(history)\n",
    "# For the rest of the conversation, the output will only include response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Questions\n",
    "\n",
    "The model has responded with an initial message. Now, you ask it a few questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting a new garden! Exciting times! Here are a few tips to help you get started:\n",
      "\n",
      "1. **Choose the right location**: Look for a spot that gets at least 6 hours of sunlight a day. Make sure the area is level and well-drained. Avoid areas with standing water or where water tends to collect.\n",
      "2. **Prepare the soil**: Test the pH level of your soil using a DIY kit or send a sample to a lab. Most vegetables and flowers prefer a slightly acidic to neutral soil pH (6.0-7.0). Add organic matter like compost or manure to improve soil structure and fertility.\n",
      "3. **Decide what to grow**: Consider your climate, available space, and personal preferences. Start with easy-to-grow plants like tomatoes, cucumbers, zucchini, carrots, and herbs like basil and cilantro.\n",
      "4. **Plan your garden**: Sketch out a rough design, considering companion planting (some plants benefit from being grown together). Make sure to leave enough space between plants for air circulation and growth.\n",
      "5. **Start small**: Begin with a manageable size garden (around 4x4 feet) and gradually expand as you gain experience.\n",
      "6. **Use good quality seeds**: Choose seeds from reputable sources, and follow the package instructions for sowing depth, spacing, and watering.\n",
      "7. **Water wisely**: Water your plants deeply but infrequently to encourage deep root growth. Avoid overhead watering, which can lead to fungal diseases.\n",
      "8. **Mulch and compost**: Mulch around plants to retain moisture, suppress weeds, and regulate soil temperature. Add compost to your soil to provide nutrients and improve its structure.\n",
      "9. **Keep a gardening journal**: Record your plantings, weather patterns, and any issues you encounter. This will help you track your progress and make adjustments for future seasons.\n",
      "10. **Be patient and flexible**: Gardening is a process, and things won't always go as planned. Be prepared to adapt to changing weather conditions, pests, and diseases.\n",
      "\n",
      "Remember, gardening is a journey, and it's okay to make mistakes. With these tips, you'll be well on your way to creating a thriving and enjoyable garden!\n"
     ]
    }
   ],
   "source": [
    "#new questions\n",
    "instructions = [{\"role\": \"user\", \"content\": \"Give me a few tips on how to start a new garden.\"}]\n",
    "response=wrapped_chain.invoke({\"input\": format_instructions(instructions)})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build on the questions\n",
    "\n",
    "Now, ask a question without mentioning the word garden to see if the model can understand the previous conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bugs in the garden! It's a natural part of the gardening process. Here are some tips to help you manage common garden pests:\n",
      "\n",
      "1. **Identify the pest**: Before you can control the bug, you need to identify what kind of bug you're dealing with. Research the common pests in your area and their habits.\n",
      "2. **Use physical barriers**: Cover your plants with fine-mesh row covers or individual plant covers to prevent bugs from reaching them.\n",
      "3. **Encourage beneficial insects**: Attract beneficial insects like ladybugs, lacewings, and parasitic wasps, which prey on common garden pests.\n",
      "4. **Use neem oil**: Neem oil is a natural insecticide that can be used to control a wide range of pests, including aphids, whiteflies, and spider mites.\n",
      "5. **Spray soaps**: Mild dish soap can be used to control soft-bodied pests like aphids and mealybugs. Mix 1 tablespoon of soap with 1 quart of water and spray on plants.\n",
      "6. **Use diatomaceous earth**: This natural powder is made from the fossilized remains of tiny aquatic organisms. It can be used to control slugs, snails, and other pests.\n",
      "7. **Remove weeds**: Weeds can provide shelter and food for pests. Remove them regularly to reduce the likelihood of infestation.\n",
      "8. **Use traps**: Use sticky traps or yellow traps to capture and remove pests like aphids, whiteflies, and moths.\n",
      "9. **Practice good garden hygiene**: Remove any infested plants or debris to prevent the spread of pests.\n",
      "10. **Use integrated pest management (IPM)**: IPM involves using a combination of techniques to manage pests, including cultural, physical, and chemical controls.\n",
      "\n",
      "Some common garden pests and their management strategies:\n",
      "\n",
      "* **Aphids**: Spray with neem oil, soap, or insecticidal soap. Introduce beneficial insects like ladybugs.\n",
      "* **Slugs and snails**: Use diatomaceous earth, copper tape, or beer traps.\n",
      "* **Cucumber beetles**: Use row covers, neem oil, or pyrethrin.\n",
      "* **Whiteflies**: Use sticky traps, neem oil, or insecticidal soap.\n",
      "* **Spider mites**: Use neem oil, soap, or insecticidal soap.\n",
      "\n",
      "Remember, it's essential to use a combination of techniques and monitor your garden regularly to stay ahead of pest problems.\n"
     ]
    }
   ],
   "source": [
    "# build on the questions\n",
    "instructions = [{\"role\": \"user\", \"content\": \"bugs\"}]\n",
    "response=wrapped_chain.invoke({\"input\": format_instructions(instructions)})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finishing this conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're welcome! It was a pleasure helping you with your questions about starting a new garden and managing common garden pests. If you have any more questions or need further assistance in the future, don't hesitate to reach out. Good luck with your gardening endeavors, and I hope you enjoy the fruits of your labor!\n"
     ]
    }
   ],
   "source": [
    "# finishing the conversation\n",
    "instructions = [{\"role\": \"user\", \"content\": \"That's all, thank you!\"}]\n",
    "response=wrapped_chain.invoke({\"input\": format_instructions(instructions)})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4.3: Chatbot using prompt template (LangChain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, you use the default PromptTemplate that is responsible for the construction of this input. LangChain provides several classes and functions to make constructing and working with prompts easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  prompt for a conversational agent\n",
    "def format_prompt(actor:str, input:str):\n",
    "    formatted_prompt: List[str] = []\n",
    "    if actor == \"system\":\n",
    "        prompt_template=\"\"\"<|begin_of_text|><|start_header_id|>{actor}<|end_header_id|>\\n{input}<|eot_id|>\"\"\"\n",
    "    elif actor == \"user\":\n",
    "        prompt_template=\"\"\"<|start_header_id|>{actor}<|end_header_id|>\\n{input}<|eot_id|>\"\"\"\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid role: {actor}. Role must be either 'user' or 'system'.\")   \n",
    "    prompt = PromptTemplate.from_template(prompt_template)     \n",
    "    formatted_prompt.extend(prompt.format(actor=actor,input=input))\n",
    "    formatted_prompt.extend([\"<|start_header_id|>assistant<|end_header_id|>\\n\"])\n",
    "    return \"\".join(formatted_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# chat user experience\n",
    "import ipywidgets as ipw\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "class ChatUX:\n",
    "    \"\"\" A chat UX using IPWidgets\n",
    "    \"\"\"\n",
    "    def __init__(self, qa, retrievalChain = False):\n",
    "        self.qa = qa\n",
    "        self.name = None\n",
    "        self.b=None\n",
    "        self.retrievalChain = retrievalChain\n",
    "        self.out = ipw.Output()\n",
    "\n",
    "\n",
    "    def start_chat(self):\n",
    "        print(\"Starting chat bot\")\n",
    "        display(self.out)\n",
    "        self.chat(None)\n",
    "\n",
    "\n",
    "    def chat(self, _):\n",
    "        if self.name is None:\n",
    "            prompt = \"\"\n",
    "        else: \n",
    "            prompt = self.name.value\n",
    "        if 'q' == prompt or 'quit' == prompt or 'Q' == prompt:\n",
    "            with self.out:\n",
    "                print(\"Thank you , that was a nice chat !!\")\n",
    "            return\n",
    "        elif len(prompt) > 0:\n",
    "            with self.out:\n",
    "                thinking = ipw.Label(value=\"Thinking...\")\n",
    "                display(thinking)\n",
    "                try:\n",
    "                    if self.retrievalChain:\n",
    "                        response = self.qa.invoke({\"input\": prompt})\n",
    "                        result=response['answer']\n",
    "                    else:\n",
    "                        instructions = [{\"role\": \"user\", \"content\": prompt}]\n",
    "                        #result = self.qa.invoke({'input': format_prompt(\"user\",prompt)}) #, 'history':chat_history})\n",
    "                        result = self.qa.invoke({\"input\": format_instructions(instructions)})\n",
    "                except:\n",
    "                    result = \"No answer\"\n",
    "                thinking.value=\"\"\n",
    "                print(f\"AI:{result}\")\n",
    "                self.name.disabled = True\n",
    "                self.b.disabled = True\n",
    "                self.name = None\n",
    "\n",
    "        if self.name is None:\n",
    "            with self.out:\n",
    "                self.name = ipw.Text(description=\"You:\", placeholder='q to quit')\n",
    "                self.b = ipw.Button(description=\"Send\")\n",
    "                self.b.on_click(self.chat)\n",
    "                display(ipw.Box(children=(self.name, self.b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, start a chat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting chat bot\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fccd3690d9e4b139d446fa6fb15e4c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start chat\n",
    "history = InMemoryChatMessageHistory() #reset chat history\n",
    "chat = ChatUX(wrapped_chain)\n",
    "chat.start_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Task 4.4: Chatbot with persona"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, Artificial Intelligence(AI) assistant plays the role of a career coach. You can inform the chatbot about its persona (or role) using a system message. Continue to leverage the InMemoryChatMessageHistory class to maintain conversational context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI is a rapidly growing field with a wide range of career options. Here are some of the most in-demand roles:\n",
      "\n",
      "1. **Machine Learning Engineer**: Design and develop machine learning models, algorithms, and systems.\n",
      "2. **Artificial Intelligence Engineer**: Develop and deploy AI and machine learning solutions, including natural language processing, computer vision, and robotics.\n",
      "3. **Data Scientist**: Analyze and interpret complex data to inform business decisions, using machine learning and AI techniques.\n",
      "4. **Natural Language Processing (NLP) Specialist**: Develop AI-powered language processing systems, including chatbots, voice assistants, and language translation tools.\n",
      "5. **Computer Vision Engineer**: Develop AI-powered computer vision systems, including image recognition, object detection, and facial recognition.\n",
      "6. **Robotics Engineer**: Design and develop intelligent robots that can perform tasks autonomously or with human assistance.\n",
      "7. **AI Researcher**: Conduct research in AI and machine learning, developing new algorithms and techniques.\n",
      "8. **AI Developer**: Develop AI-powered applications, including games, virtual assistants, and other software.\n",
      "9. **Business Intelligence Analyst**: Use AI and machine learning to analyze and interpret business data, identifying trends and opportunities.\n",
      "10. **AI Ethicist**: Develop and implement AI systems that are ethical, transparent, and responsible.\n",
      "11. **AI Project Manager**: Oversee AI projects, ensuring they are completed on time, within budget, and to the required quality standards.\n",
      "12. **AI Quality Assurance Engineer**: Test and validate AI-powered systems, ensuring they meet required standards and are free from errors.\n",
      "13. **AI Technical Writer**: Create documentation and training materials for AI-powered systems, ensuring users understand how to use them effectively.\n",
      "14. **AI Business Development Manager**: Identify new business opportunities and partnerships for AI-powered solutions.\n",
      "15. **AI Sales Representative**: Sell AI-powered solutions to businesses and organizations.\n",
      "\n",
      "These are just a few examples of the many career options available in AI. As the field continues to evolve, new roles and specializations will emerge.\n"
     ]
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \" You will be acting as a career coach. Your goal is to give career advice to users. For questions that are not career related, don't provide advice. Say, I don't know.\"),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "history = InMemoryChatMessageHistory() # reset history\n",
    "\n",
    "chain = prompt | chat_model | StrOutputParser()\n",
    "\n",
    "wrapped_chain = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_history,\n",
    "    history_messages_key=\"career_chat_history\",\n",
    ")\n",
    "\n",
    "response=wrapped_chain.invoke({\"input\": \"What are the career options in AI?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm a career coach, not a mechanic! I don't know how to fix your car. You might want to consult a trusted mechanic or a repair manual for your specific vehicle.\n"
     ]
    }
   ],
   "source": [
    "response=wrapped_chain.invoke({\"input\": \"How to fix my car?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: What are the career options in AI?\n",
      "AI: AI is a rapidly growing field with a wide range of career options. Here are some of the most in-demand roles:\n",
      "\n",
      "1. **Machine Learning Engineer**: Design and develop machine learning models, algorithms, and systems.\n",
      "2. **Artificial Intelligence Engineer**: Develop and deploy AI and machine learning solutions, including natural language processing, computer vision, and robotics.\n",
      "3. **Data Scientist**: Analyze and interpret complex data to inform business decisions, using machine learning and AI techniques.\n",
      "4. **Natural Language Processing (NLP) Specialist**: Develop AI-powered language processing systems, including chatbots, voice assistants, and language translation tools.\n",
      "5. **Computer Vision Engineer**: Develop AI-powered computer vision systems, including image recognition, object detection, and facial recognition.\n",
      "6. **Robotics Engineer**: Design and develop intelligent robots that can perform tasks autonomously or with human assistance.\n",
      "7. **AI Researcher**: Conduct research in AI and machine learning, developing new algorithms and techniques.\n",
      "8. **AI Developer**: Develop AI-powered applications, including games, virtual assistants, and other software.\n",
      "9. **Business Intelligence Analyst**: Use AI and machine learning to analyze and interpret business data, identifying trends and opportunities.\n",
      "10. **AI Ethicist**: Develop and implement AI systems that are ethical, transparent, and responsible.\n",
      "11. **AI Project Manager**: Oversee AI projects, ensuring they are completed on time, within budget, and to the required quality standards.\n",
      "12. **AI Quality Assurance Engineer**: Test and validate AI-powered systems, ensuring they meet required standards and are free from errors.\n",
      "13. **AI Technical Writer**: Create documentation and training materials for AI-powered systems, ensuring users understand how to use them effectively.\n",
      "14. **AI Business Development Manager**: Identify new business opportunities and partnerships for AI-powered solutions.\n",
      "15. **AI Sales Representative**: Sell AI-powered solutions to businesses and organizations.\n",
      "\n",
      "These are just a few examples of the many career options available in AI. As the field continues to evolve, new roles and specializations will emerge.\n",
      "Human: How to fix my car?\n",
      "AI: I'm a career coach, not a mechanic! I don't know how to fix your car. You might want to consult a trusted mechanic or a repair manual for your specific vehicle.\n"
     ]
    }
   ],
   "source": [
    "print(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, ask a question that is not within this persona's specialty. The model should not answer that question and should give a reason for that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4.5 Chatbot with Context\n",
    "\n",
    "In this task, you ask the chatbot to answer questions based on context that was passed to it. You take a CSV file and use the Titan embeddings model to create a vector representing that context. This vector is stored in Facebook AI Similarity Search (FAISS). When the chatbot is asked a question, you will pass this vector back to the chatbot and have it retrieve the answer using the vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Titan embeddings Model\n",
    "\n",
    "Embeddings represent words, phrases, or any other discrete items as vectors in a continuous vector space. This allows machine learning models to perform mathematical operations on these representations and capture semantic relationships between them.\n",
    "\n",
    "You use embeddings for the Retrieval-Augmented Generation (RAG) [document search capability](https://labelbox.com/blog/how-vector-similarity-search-works/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model configuration\n",
    "from langchain_aws.embeddings import BedrockEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "br_embeddings = BedrockEmbeddings(model_id=\"amazon.titan-embed-text-v1\", client=bedrock_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FAISS as VectorStore\n",
    "\n",
    "In order to use embeddings for search, you need a store that can efficiently perform vector similarity searches. In this notebook, you use FAISS, which is an in-memory store. To permanently store vectors, you can use Knowledge Bases for Amazon Bedrock, pgVector, Pinecone, Weaviate, or Chroma.\n",
    "\n",
    "The LangChain VectorStore APIs are available [here](https://python.langchain.com/v0.2/docs/integrations/vectorstores/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "documents:loaded:size=153\n",
      "Documents:after split and chunking size=154\n",
      "vectorstore_faiss_aws:created=<langchain_community.vectorstores.faiss.FAISS object at 0x7f64ef0711d0>::\n"
     ]
    }
   ],
   "source": [
    "# vector store\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
    "\n",
    "loader = CSVLoader(\"../rag_data/Amazon_SageMaker_FAQs.csv\") # --- > 219 docs with 400 chars\n",
    "documents_aws = loader.load() #\n",
    "print(f\"documents:loaded:size={len(documents_aws)}\")\n",
    "\n",
    "docs = CharacterTextSplitter(chunk_size=2000, chunk_overlap=400, separator=\",\").split_documents(documents_aws)\n",
    "\n",
    "print(f\"Documents:after split and chunking size={len(docs)}\")\n",
    "vectorstore_faiss_aws = None\n",
    "try:\n",
    "    \n",
    "    vectorstore_faiss_aws = FAISS.from_documents(\n",
    "        documents=docs,\n",
    "        embedding = br_embeddings, \n",
    "        #**k_args\n",
    "    )\n",
    "\n",
    "    print(f\"vectorstore_faiss_aws:created={vectorstore_faiss_aws}::\")\n",
    "\n",
    "except ValueError as error:\n",
    "    if  \"AccessDeniedException\" in str(error):\n",
    "        print(f\"\\x1b[41m{error}\\\n",
    "        \\nTo troubeshoot this issue please refer to the following resources.\\\n",
    "         \\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/troubleshoot_access-denied.html\\\n",
    "         \\nhttps://docs.aws.amazon.com/bedrock/latest/userguide/security-iam.html\\x1b[0m\\n\")      \n",
    "        class StopExecution(ValueError):\n",
    "            def _render_traceback_(self):\n",
    "                pass\n",
    "        raise StopExecution        \n",
    "    else:\n",
    "        raise error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run a quick low code test \n",
    "\n",
    "You can use a Wrapper class provided by LangChain to query the vector database store and return the relevant documents. This runs a QA Chain with all default values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, R is supported with Amazon SageMaker. You can use R within SageMaker notebook instances, which include a preinstalled R kernel and the reticulate library. Reticulate offers an R interface for the Amazon SageMaker Python SDK, enabling ML practitioners to build, train, tune, and deploy R models.\n"
     ]
    }
   ],
   "source": [
    "chat_llm=ChatBedrock(\n",
    "    model_id=\"amazon.titan-text-premier-v1:0\" , \n",
    "    client=bedrock_client)\n",
    "# wrapper store faiss\n",
    "wrapper_store_faiss = VectorStoreIndexWrapper(vectorstore=vectorstore_faiss_aws)\n",
    "print(wrapper_store_faiss.query(\"R in SageMaker\", llm=chat_llm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chatbot application\n",
    "\n",
    "For the chatbot, you need context management, history, vector stores, and many other components. You start by building a Retrieval Augmented Generation (RAG) chain that supports context.\n",
    "\n",
    "This uses the **create_stuff_documents_chain** and **create_retrieval_chain** functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters and functions used for RAG\n",
    "\n",
    "- **Retriever:** You used `VectorStoreRetriever`, which is backed by a `VectorStore`. To retrieve text, there are two search types to choose from: `\"similarity\"` or `\"mmr\"`. `search_type=\"similarity\"` uses similarity search in the retriever object, where it selects text chunk vectors that are most similar to the question vector.\n",
    "\n",
    "- **create_stuff_documents_chain** specifies how retrieved context is fed into a prompt and LLM. Retrieved documents are \"stuffed\" as context without any summarization or other processing into the prompt.\n",
    "\n",
    "- **create_retrieval_chain** adds the retrieval step and propagates the retrieved context through the chain, providing it alongside the final answer. \n",
    "\n",
    "If the question asked falls outside the scope of the context, the model will reply that it doesn't know the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'What is sagemaker?', 'context': [Document(metadata={'source': '../rag_data/Amazon_SageMaker_FAQs.csv', 'row': 7}, page_content='\\ufeffWhat is Amazon SageMaker?: What if I have my own notebook, training, or hosting environment?\\nAmazon SageMaker is a fully managed service to prepare data and build, train, and deploy machine learning (ML) models for any use case with fully managed infrastructure, tools, and workflows.: Amazon SageMaker provides a full end-to-end workflow, but you can continue to use your existing tools with SageMaker. You can easily transfer the results of each stage in and out of SageMaker as your business requirements dictate.'), Document(metadata={'source': '../rag_data/Amazon_SageMaker_FAQs.csv', 'row': 12}, page_content='\\ufeffWhat is Amazon SageMaker?: What is Amazon SageMaker Studio?\\nAmazon SageMaker is a fully managed service to prepare data and build, train, and deploy machine learning (ML) models for any use case with fully managed infrastructure, tools, and workflows.: Amazon SageMaker Studio provides a single, web-based visual interface where you can perform all ML development steps. SageMaker Studio gives you complete access, control, and visibility into each step required to prepare data and build, train, and deploy models. You can quickly upload data, create new notebooks, train and tune models, move back and forth between steps to adjust experiments, compare results, and deploy models to production all in one place, making you much more productive. All ML development activities including notebooks, experiment management, automatic model creation, debugging and profiling, and model drift detection can be performed within the unified SageMaker Studio visual interface.'), Document(metadata={'source': '../rag_data/Amazon_SageMaker_FAQs.csv', 'row': 92}, page_content='\\ufeffWhat is Amazon SageMaker?: What algorithms does Amazon SageMaker use to generate models?\\nAmazon SageMaker is a fully managed service to prepare data and build, train, and deploy machine learning (ML) models for any use case with fully managed infrastructure, tools, and workflows.: Amazon SageMaker includes built-in algorithms for linear regression, logistic regression, k-means clustering, principal component analysis, factorization machines, neural topic modeling, latent dirichlet allocation, gradient boosted trees, sequence2sequence, time-series forecasting, word2vec, and image classification. SageMaker also provides optimized Apache MXNet, Tensorflow, Chainer, PyTorch, Gluon, Keras, Horovod, Scikit-learn, and Deep Graph Library containers. In addition, Amazon SageMaker supports your custom training algorithms provided through a Docker image adhering to the documented specification.'), Document(metadata={'source': '../rag_data/Amazon_SageMaker_FAQs.csv', 'row': 44}, page_content='\\ufeffWhat is Amazon SageMaker?: How does Amazon SageMaker Data Wrangler work with my CI/CD processes?\\nAmazon SageMaker is a fully managed service to prepare data and build, train, and deploy machine learning (ML) models for any use case with fully managed infrastructure, tools, and workflows.: Once you have prepared your data, Amazon SageMaker Data Wrangler provides different options for promoting your SageMaker Data Wrangler flow to production and integrates seamlessly with MLOps and CI/CD capabilities. You can configure and launch SageMaker processing jobs directly from the SageMaker Data Wrangler UI, including scheduling your data processing job and parametrizing your data sources to easily transform new batches of data at scale. Alternatively, SageMaker Data Wrangler integrates seamlessly with SageMaker processing and the SageMaker Spark container, allowing you to easily use SageMaker SDKs to integrate SageMaker Data Wrangler into your production workflow.')], 'answer': 'Amazon SageMaker is a fully managed service to prepare data and build, train, and deploy machine learning (ML) models for any use case with fully managed infrastructure, tools, and workflows.'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "retriever=vectorstore_faiss_aws.as_retriever()\n",
    "question_answer_chain = create_stuff_documents_chain(chat_llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "\n",
    "response = rag_chain.invoke({\"input\": \"What is sagemaker?\"})\n",
    "print(response) # shows the document chunks consulted to come up with the answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, start a chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting chat bot\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2308bc1ee1de4bf7afaf9e5de2215822",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chat = ChatUX(rag_chain, retrievalChain=True)\n",
    "chat.start_chat()  # Only answers will be shown here, and not the citations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "You have utilized Titan LLM to create a conversational interface with following patterns:\n",
    "\n",
    "- Chatbot (Basic - without context)\n",
    "- Chatbot using prompt template(Langchain)\n",
    "- Chatbot with personas\n",
    "- Chatbot with context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try it yourself\n",
    "\n",
    "- Change the prompts to your specific usecase and evaluate the output of different models.\n",
    "- Play with the token length to understand the latency and responsiveness of the service.\n",
    "- Apply different prompt engineering principles to get better outputs.\n",
    "\n",
    "### Cleanup\n",
    "\n",
    "You have completed this notebook. To move to the next part of the lab, do the following:\n",
    "\n",
    "- Close this notebook file and continue with **Task 5**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
